{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data1/ameenali/miniconda3/envs/github/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from timm.models import create_model\n",
    "import models_mamba\n",
    "import utils\n",
    "import os\n",
    "from xai_utils import *\n",
    "from class_mapper import CLS2IDX\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load Model</h1>\n",
    "Make sure to speiciy the model checkpoint path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = 'vim_small_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2'\n",
    "model_path = './vim_s_midclstok_80p5acc.pth'\n",
    "num_classes = 1000\n",
    "model = create_model(\n",
    "    model_type,\n",
    "    pretrained=False,\n",
    "    num_classes=num_classes,\n",
    "    drop_rate=0,\n",
    "    drop_path_rate=0,\n",
    "    drop_block_rate=None,\n",
    "    img_size=224\n",
    ")\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Auxiliary Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "IMAGENET_DEFAULT_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_DEFAULT_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "def transform_for_eval(image_path, input_size=224):\n",
    "    transform_eval = transforms.Compose([\n",
    "        transforms.Resize(int(input_size)),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "    ])\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transformed_img = transform_eval(img)\n",
    "    return transformed_img\n",
    "\n",
    "import cv2\n",
    "\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return cam\n",
    "\n",
    "\n",
    "def generate_visualization(original_image, transformer_attribution):\n",
    "    transformer_attribution = transformer_attribution.reshape(1, 1, 14, 14)\n",
    "    transformer_attribution = torch.nn.functional.interpolate(transformer_attribution, scale_factor=16, mode='bilinear')\n",
    "    transformer_attribution = transformer_attribution.reshape(224, 224).cuda().data.cpu().numpy()\n",
    "    transformer_attribution = (transformer_attribution - transformer_attribution.min()) / (transformer_attribution.max() - transformer_attribution.min())\n",
    "    image_transformer_attribution = original_image.permute(1, 2, 0).data.cpu().numpy()\n",
    "    image_transformer_attribution = (image_transformer_attribution - image_transformer_attribution.min()) / (image_transformer_attribution.max() - image_transformer_attribution.min())\n",
    "    vis = show_cam_on_image(image_transformer_attribution, transformer_attribution)\n",
    "    vis =  np.uint8(255 * vis)\n",
    "    vis = cv2.cvtColor(np.array(vis), cv2.COLOR_RGB2BGR)\n",
    "    return vis\n",
    "\n",
    "def print_preds(logits):\n",
    "    prob = torch.softmax(logits, dim=1)\n",
    "    class_indices = logits.data.topk(5, dim=1)[1][0].tolist()\n",
    "    max_str_len = 0\n",
    "    class_names = []\n",
    "    for cls_idx in class_indices:\n",
    "        class_names.append(CLS2IDX[cls_idx])\n",
    "        if len(CLS2IDX[cls_idx]) > max_str_len:\n",
    "            max_str_len = len(CLS2IDX[cls_idx])\n",
    "\n",
    "    print('Top 5 classes:')\n",
    "    for cls_idx in class_indices:\n",
    "        output_string = '\\t{} : {}'.format(cls_idx, CLS2IDX[cls_idx])\n",
    "        output_string += ' ' * (max_str_len - len(CLS2IDX[cls_idx])) + '\\t\\t'\n",
    "        output_string += 'value = {:.3f}\\t prob = {:.1f}%'.format(logits[0, cls_idx], 100 * prob[0, cls_idx])\n",
    "        print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'JpegImageFile' object has no attribute 'permute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m map_rollout, _ \u001b[38;5;241m=\u001b[39m generate_rollout(model, image)\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m----> 8\u001b[0m raw_attn \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_visualization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_raw_atten\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m mamba_attr \u001b[38;5;241m=\u001b[39m generate_visualization(raw_image, map_mamba_attr)\n\u001b[1;32m     10\u001b[0m rollout \u001b[38;5;241m=\u001b[39m generate_visualization(raw_image, map_rollout)\n",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m, in \u001b[0;36mgenerate_visualization\u001b[0;34m(original_image, transformer_attribution)\u001b[0m\n\u001b[1;32m     37\u001b[0m transformer_attribution \u001b[38;5;241m=\u001b[39m transformer_attribution\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     38\u001b[0m transformer_attribution \u001b[38;5;241m=\u001b[39m (transformer_attribution \u001b[38;5;241m-\u001b[39m transformer_attribution\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (transformer_attribution\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m transformer_attribution\u001b[38;5;241m.\u001b[39mmin())\n\u001b[0;32m---> 39\u001b[0m image_transformer_attribution \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     40\u001b[0m image_transformer_attribution \u001b[38;5;241m=\u001b[39m (image_transformer_attribution \u001b[38;5;241m-\u001b[39m image_transformer_attribution\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (image_transformer_attribution\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m image_transformer_attribution\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m     41\u001b[0m vis \u001b[38;5;241m=\u001b[39m show_cam_on_image(image_transformer_attribution, transformer_attribution)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'JpegImageFile' object has no attribute 'permute'"
     ]
    }
   ],
   "source": [
    "image  = transform_for_eval('./images/1.jpg').unsqueeze(0).cuda()\n",
    "raw_image = Image.open('./images/1.jpg')\n",
    "map_raw_atten, logits = generate_raw_attn(model, image)\n",
    "map_mamba_attr, _ = generate_mamba_attr(model, image)\n",
    "map_rollout, _ = generate_rollout(model, image)\n",
    "image = image.squeeze()\n",
    "\n",
    "raw_attn = generate_visualization(invTrans(image).detach().cpu(), map_raw_atten)\n",
    "mamba_attr = generate_visualization(invTrans(image).detach().cpu(), map_mamba_attr)\n",
    "rollout = generate_visualization(invTrans(image).detach().cpu(), map_rollout)\n",
    "print_preds(logits)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10,10))\n",
    "axs[0].imshow(raw_image)\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(raw_attn)\n",
    "axs[1].axis('off')\n",
    "axs[2].imshow(rollout)\n",
    "axs[2].axis('off')\n",
    "axs[3].imshow(mamba_attr)\n",
    "axs[3].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image  = transform_for_eval('./images/2.jpg').unsqueeze(0).cuda()\n",
    "raw_image = Image.open('./images/2.jpg')\n",
    "map_raw_atten, logits = generate_raw_attn(model, image)\n",
    "map_mamba_attr, _ = generate_mamba_attr(model, image)\n",
    "map_rollout, _ = generate_rollout(model, image)\n",
    "image = image.squeeze()\n",
    "\n",
    "raw_attn = generate_visualization(invTrans(image).detach().cpu(), map_raw_atten)\n",
    "mamba_attr = generate_visualization(invTrans(image).detach().cpu(), map_mamba_attr)\n",
    "rollout = generate_visualization(invTrans(image).detach().cpu(), map_rollout)\n",
    "print_preds(logits)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10,10))\n",
    "axs[0].imshow(raw_image)\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(raw_attn)\n",
    "axs[1].axis('off')\n",
    "axs[2].imshow(rollout)\n",
    "axs[2].axis('off')\n",
    "axs[3].imshow(mamba_attr)\n",
    "axs[3].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image  = transform_for_eval('./images/3.jpg').unsqueeze(0).cuda()\n",
    "raw_image = Image.open('./images/3.jpg')\n",
    "map_raw_atten, logits = generate_raw_attn(model, image)\n",
    "map_mamba_attr, _ = generate_mamba_attr(model, image)\n",
    "map_rollout, _ = generate_rollout(model, image)\n",
    "image = image.squeeze()\n",
    "\n",
    "raw_attn = generate_visualization(invTrans(image).detach().cpu(), map_raw_atten)\n",
    "mamba_attr = generate_visualization(invTrans(image).detach().cpu(), map_mamba_attr)\n",
    "rollout = generate_visualization(invTrans(image).detach().cpu(), map_rollout)\n",
    "print_preds(logits)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10,10))\n",
    "axs[0].imshow(raw_image)\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(raw_attn)\n",
    "axs[1].axis('off')\n",
    "axs[2].imshow(rollout)\n",
    "axs[2].axis('off')\n",
    "axs[3].imshow(mamba_attr)\n",
    "axs[3].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image  = transform_for_eval('./images/4.jpg').unsqueeze(0).cuda()\n",
    "raw_image = Image.open('./images/4.jpg')\n",
    "map_raw_atten, logits = generate_raw_attn(model, image)\n",
    "map_mamba_attr, _ = generate_mamba_attr(model, image)\n",
    "map_rollout, _ = generate_rollout(model, image)\n",
    "image = image.squeeze()\n",
    "\n",
    "raw_attn = generate_visualization(invTrans(image).detach().cpu(), map_raw_atten)\n",
    "mamba_attr = generate_visualization(invTrans(image).detach().cpu(), map_mamba_attr)\n",
    "rollout = generate_visualization(invTrans(image).detach().cpu(), map_rollout)\n",
    "print_preds(logits)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10,10))\n",
    "axs[0].imshow(raw_image)\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(raw_attn)\n",
    "axs[1].axis('off')\n",
    "axs[2].imshow(rollout)\n",
    "axs[2].axis('off')\n",
    "axs[3].imshow(mamba_attr)\n",
    "axs[3].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image  = transform_for_eval('./images/5.jpg').unsqueeze(0).cuda()\n",
    "raw_image = Image.open('./images/5.jpg')\n",
    "map_raw_atten, logits = generate_raw_attn(model, image)\n",
    "map_mamba_attr, _ = generate_mamba_attr(model, image)\n",
    "map_rollout, _ = generate_rollout(model, image)\n",
    "image = image.squeeze()\n",
    "\n",
    "raw_attn = generate_visualization(invTrans(image).detach().cpu(), map_raw_atten)\n",
    "mamba_attr = generate_visualization(invTrans(image).detach().cpu(), map_mamba_attr)\n",
    "rollout = generate_visualization(invTrans(image).detach().cpu(), map_rollout)\n",
    "print_preds(logits)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10,10))\n",
    "axs[0].imshow(raw_image)\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(raw_attn)\n",
    "axs[1].axis('off')\n",
    "axs[2].imshow(rollout)\n",
    "axs[2].axis('off')\n",
    "axs[3].imshow(mamba_attr)\n",
    "axs[3].axis('off')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
